general:
  remote_storage: s3
  upload_concurrency: 4
  download_concurrency: 4
  skip_tables:
    - " system.*"
    - "INFORMATION_SCHEMA.*"
    - "information_schema.*"
    - "_temporary_and_external_tables.*"
  restore_schema_on_cluster: "{cluster}"
clickhouse:
  host: clickhouse
  port: 9440
  username: backup
  password: meow=& 123?*%# МЯУ
  secure: true
  skip_verify: true
  sync_replicated_tables: true
  timeout: 1h
  restart_command: bash -c 'echo "FAKE RESTART"'
  backup_mutations: true
# secrets for `FISP` will provide from `.env` or from GitHub actions secrets
s3:
  access_key: ${QA_AWS_ACCESS_KEY}
  secret_key: ${QA_AWS_SECRET_KEY}
  bucket: ${QA_AWS_BUCKET}
#  endpoint: https://${QA_AWS_BUCKET}.s3-fips.${QA_AWS_REGION}.amazonaws.com/
  region: ${QA_AWS_REGION}
  acl: private
  force_path_style: false
  path: backup/{cluster}/{shard}
  object_disk_path: object_disks/{cluster}/{shard}
  disable_ssl: false
  compression_format: tar
  allow_multipart_download: false
  concurrency: 4
  # storage_class: GLACIER, 6000 seconds test execution
  storage_class: GLACIER_IR
api:
  listen: :7171
  create_integration_tables: true
  integration_tables_host: "localhost"
  allow_parallel: false